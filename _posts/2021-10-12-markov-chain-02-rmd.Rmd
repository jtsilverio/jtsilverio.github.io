---
layout: post
title: "Entendendo um pouco de Markov Chains"
author: "Jefferson"
date: '2021-05-21'
categories:
    - R
    - Markov
output:
    html_document:
        theme: null
        self_contained: true
        highlight: pygments
---

# Simulando Cadeias de Markov no R

Para simularmos uma cadeia de Markov precisamos definir nossa matriz de transição. Essa matriz mostra as probabilidades de transições entre os estados. As linhas da matriz representam o estado atual e as colunas o próximo estado na cadeia. Vamos simular as transições entre repouso e atividade de um animal, assumindo que esse animal é arritmico. Esse animal quando em repouso tende a permanecer em repouso 90% das vezes. Agora, se esse animal está em atividade a chance dele entrar em repouso ou permanecer em atividade é a mesma: 50%. Com esses dados, nossa matriz de transição fica assim: 

```{r}
states = c("repouso", "atividade")
(transition_matrix = matrix(c(0.9, 0.1, 0.5, 0.5), byrow = T, nrow = 2, dimnames = list(states,states)))
```

O próximo passo é simular as mudanças de estado a partir de um estado inicial. Para isso vamos definir também uma matriz 1x2 com as probabilidades do sistema começar em cada um dos estado. Nesse exemplo a probabilidade do animal iniciar em atividade ou repouso é a mesma, 50% para cada.

```{r}
(initial_prob = matrix(c(0.5, 0.5), nrow = 1, dimnames = list(c(),states)))
```

Com essas probabilidades inicias e a matriz de transição podemos simular algumas cadeias de Markov.
Vamos simular 9 cadeias de Markov com 500 transições cada. Cada transição é correspondente a uma unidade de tempo em que estamos coletando os dados, o que poderia corresponder a minutos ou horas dependendo do tipo de coleta.

```{r}
set.seed(53)

# Quantas simulações e probabilidades iniciais
nchains  = 9
niter = 500

# Function that simulates a Markov Chain given a 
# vector containing the starting state in position 1
markov_chain_sim = function(transition_matrix, initial_prob, niter = 50){
    nstates = nrow(transition_matrix)
    chain = numeric(niter)
    
    #Sorteia os estados iniciais de acordo com a matriz de prob.
    chain[1] = sample(1:nstates, 1, prob = t(initial_prob))
    
    for(t in 2:niter){
        chain[t] = sample(1:nstates, 1, prob = transition_matrix[chain[t-1],])
    }
    
    return(chain)
}

#' Criando uma matrix que conterá todas simulações
#' Cada coluna é uma simulação diferente.
#' O número de linhas corresponde à quantidade de transições que queremos simular
sim = matrix(NA, niter, nchains)
colnames(sim) = paste0("sim", 1:nchains) 

# Repetimos a função markov_chain_sim para cada coluna
for(i in 1:nchains){
    sim[,i] = markov_chain_sim(transition_matrix, initial_prob, niter) 
}

tail(sim)
```

# Visualizando os resultados

Vamos plotar esses os resultados de algumas simulaçoes para entendermos como o sistema está mudando no tempo. Podemos ver no gráfico abaixo que pela Cadeia de Markov ser um processo estocástico nenhuma das simualções é igual a outra.

```{r line-plot}
library(ggplot2)
library(tidyr)
library(dplyr)

sim_df = pivot_longer(data.frame(time = 1:nrow(sim), sim), cols = 2:(ncol(sim)+1), names_to = "sim", values_to = "state")

ggplot(sim_df) +
    geom_line(aes(x = time, y = state)) +
    scale_y_continuous(breaks = unique(sim_df$state), labels = states) +
    facet_wrap(vars(sim)) +
    theme_minimal()
```
Ou seja, não é possível prever com certeza o que acontecerá no futuro dado que temos em qual estado o animals começou seu registro. Porém existem algumas propriedades estatísticas importantes. Porém, o que é interessante é que se calcularmos a proporção de repouso e atividade sobre o total de observações, que no nosso caso são 500, vamos obter um resultado muito próximo entre as simulações.

```{r}
sim_perc = sim_df %>% 
    group_by(sim, state) %>% 
    summarise(perc = n()/niter)

head(sim_perc)
```

Essa tabela num gráfico de barras ficas assim:

```{r bar-plot}
ggplot(sim_perc, aes(y = perc, x = factor(state), fill = factor(state))) +
    geom_bar(stat = "identity") +
    scale_x_discrete(breaks = unique(sim_df$state), labels = states) +
    facet_wrap(vars(sim)) +
    theme_minimal() +
    xlab("") +
    ylab("Porcentagem no Estado")
```

O fato das simulações se estabilizarem em certas proporções não é uma coindicência. Essa era justamente a propriedade que Markov queria demonstrar. Dado algumas condições para a cadeia e um número de observações suficientes as proporções vão se estabilizar ao redor de algum valor mesmo que as observações não sejam totalmente independentes entre si.

# Usando Matrizes

Ao invés de simularmos uma sequência de transições e só depois calcularmos as proporções dos estados podemos fazer isso com matrizes. Para isso multiplicamos a matriz de transição pela matriz de probabilidades iniciais. O resultado é então multiplicado pela matriz de transição. Esse processo é repetido até o número de iterações, ou tempo, que queremos que a cadeia tenha.

```{r}
niter = 500

step =  initial_prob %*% transition_matrix
for (i in 1:niter){
    step = step %*% transition_matrix
}

step
```

```{r}
# sim_prop = data.frame(x = 1:niter, y = apply(sim, 1, function(x){sum(x == 1)/nchains}))
# 
# ggplot(sim_prop, aes(x, y)) +
#       geom_line() +
#       labs(x = "Iteration",
#            y = "Prop.") +
#       theme_minimal(base_size = 16)
```

# Outros Links

- https://willhipson.netlify.app/post/markov-sim/markov_chain/
- https://a-little-book-of-r-for-bioinformatics.readthedocs.io/en/latest/src/chapter10.html
- http://recologia.com.br/2013/03/13/um-exemplo-de-markov-chain/
- https://towardsdatascience.com/markov-models-and-markov-chains-explained-in-real-life-probabilistic-workout-routine-65e47b5c9a73
- https://www.stat.auckland.ac.nz/~fewster/325/notes/ch8.pdf




