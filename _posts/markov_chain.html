<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Jefferson" />

<meta name="date" content="2021-05-21" />

<title>Entendendo um pouco de Markov Chains</title>

<script src="markov_chain_files/header-attrs-2.11/header-attrs.js"></script>
<link href="markov_chain_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="markov_chain_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









</head>

<body>




<h1 class="title toc-ignore">Entendendo um pouco de Markov Chains</h1>
<h4 class="author">Jefferson</h4>
<h4 class="date">2021-05-21</h4>



<div id="simulando-cadeias-de-markov-no-r" class="section level1">
<h1>Simulando Cadeias de Markov no R</h1>
<p>Para simularmos uma cadeia de Markov precisamos definir nossa matriz de transição. Essa matriz mostra as probabilidades de transições entre os estados. As linhas da matriz representam o estado atual e as colunas o próximo estado na cadeia. Vamos simular as transições entre repouso e atividade de um animal, assumindo que esse animal é arritmico. Esse animal quando em repouso tende a permanecer em repouso 90% das vezes. Agora, se esse animal está em atividade a chance dele entrar em repouso ou permanecer em atividade é a mesma: 50%. Com esses dados, nossa matriz de transição fica assim:</p>
<pre class="r"><code>states = c(&quot;repouso&quot;, &quot;atividade&quot;)
(transition_matrix = matrix(c(0.9, 0.1, 0.5, 0.5), byrow = T, nrow = 2, dimnames = list(states,states)))</code></pre>
<pre><code>##           repouso atividade
## repouso       0.9       0.1
## atividade     0.5       0.5</code></pre>
<p>O próximo passo é simular as mudanças de estado a partir de um estado inicial. Para isso vamos definir também uma matriz 1x2 com as probabilidades do sistema começar em cada um dos estado. Nesse exemplo a probabilidade do animal iniciar em atividade ou repouso é a mesma, 50% para cada.</p>
<pre class="r"><code>(initial_prob = matrix(c(0.5, 0.5), nrow = 1, dimnames = list(c(),states)))</code></pre>
<pre><code>##      repouso atividade
## [1,]     0.5       0.5</code></pre>
<p>Com essas probabilidades inicias e a matriz de transição podemos simular algumas cadeias de Markov. Vamos simular 9 cadeias de Markov com 500 transições cada. Cada transição é correspondente a uma unidade de tempo em que estamos coletando os dados, o que poderia corresponder a minutos ou horas dependendo do tipo de coleta.</p>
<pre class="r"><code>set.seed(53)

# Quantas simulações e probabilidades iniciais
nchains  = 9
niter = 500

# Function that simulates a Markov Chain given a 
# vector containing the starting state in position 1
markov_chain_sim = function(transition_matrix, initial_prob, niter = 50){
    nstates = nrow(transition_matrix)
    chain = numeric(niter)
    
    #Sorteia os estados iniciais de acordo com a matriz de prob.
    chain[1] = sample(1:nstates, 1, prob = t(initial_prob))
    
    for(t in 2:niter){
        chain[t] = sample(1:nstates, 1, prob = transition_matrix[chain[t-1],])
    }
    
    return(chain)
}

#&#39; Criando uma matrix que conterá todas simulações
#&#39; Cada coluna é uma simulação diferente.
#&#39; O número de linhas corresponde à quantidade de transições que queremos simular
sim = matrix(NA, niter, nchains)
colnames(sim) = paste0(&quot;sim&quot;, 1:nchains) 

# Repetimos a função markov_chain_sim para cada coluna
for(i in 1:nchains){
    sim[,i] = markov_chain_sim(transition_matrix, initial_prob, niter) 
}

tail(sim)</code></pre>
<pre><code>##        sim1 sim2 sim3 sim4 sim5 sim6 sim7 sim8 sim9
## [495,]    1    2    2    1    1    1    1    1    1
## [496,]    1    1    1    1    1    1    1    1    1
## [497,]    1    2    1    1    1    1    1    1    1
## [498,]    1    2    1    1    1    1    1    1    1
## [499,]    1    1    2    1    1    2    1    1    1
## [500,]    1    2    2    1    1    1    1    1    1</code></pre>
</div>
<div id="visualizando-os-resultados" class="section level1">
<h1>Visualizando os resultados</h1>
<p>Vamos plotar esses os resultados de algumas simulaçoes para entendermos como o sistema está mudando no tempo. Podemos ver no gráfico abaixo que pela Cadeia de Markov ser um processo estocástico nenhuma das simualções é igual a outra.</p>
<pre class="r"><code>library(ggplot2)
library(tidyr)
library(dplyr)</code></pre>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre class="r"><code>sim_df = pivot_longer(data.frame(time = 1:nrow(sim), sim), cols = 2:(ncol(sim)+1), names_to = &quot;sim&quot;, values_to = &quot;state&quot;)

ggplot(sim_df) +
    geom_line(aes(x = time, y = state)) +
    scale_y_continuous(breaks = unique(sim_df$state), labels = states) +
    facet_wrap(vars(sim)) +
    theme_minimal()</code></pre>
<p><img src="markov_chain_files/figure-html/line-plot-1.png" width="672" /> Ou seja, não é possível prever com certeza o que acontecerá no futuro dado que temos em qual estado o animals começou seu registro. Porém existem algumas propriedades estatísticas importantes. Porém, o que é interessante é que se calcularmos a proporção de repouso e atividade sobre o total de observações, que no nosso caso são 500, vamos obter um resultado muito próximo entre as simulações.</p>
<pre class="r"><code>sim_perc = sim_df %&gt;% 
    group_by(sim, state) %&gt;% 
    summarise(perc = n()/niter)</code></pre>
<pre><code>## `summarise()` has grouped output by &#39;sim&#39;. You can override using the `.groups` argument.</code></pre>
<pre class="r"><code>head(sim_perc)</code></pre>
<pre><code>## # A tibble: 6 × 3
## # Groups:   sim [3]
##   sim   state  perc
##   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 sim1      1 0.83 
## 2 sim1      2 0.17 
## 3 sim2      1 0.828
## 4 sim2      2 0.172
## 5 sim3      1 0.796
## 6 sim3      2 0.204</code></pre>
<p>Essa tabela num gráfico de barras ficas assim:</p>
<pre class="r"><code>ggplot(sim_perc, aes(y = perc, x = factor(state), fill = factor(state))) +
    geom_bar(stat = &quot;identity&quot;) +
    scale_x_discrete(breaks = unique(sim_df$state), labels = states) +
    facet_wrap(vars(sim)) +
    theme_minimal() +
    xlab(&quot;&quot;) +
    ylab(&quot;Porcentagem no Estado&quot;)</code></pre>
<p><img src="markov_chain_files/figure-html/bar-plot-1.png" width="672" /></p>
<p>O fato das simulações se estabilizarem em certas proporções não é uma coindicência. Essa era justamente a propriedade que Markov queria demonstrar. Dado algumas condições para a cadeia e um número de observações suficientes as proporções vão se estabilizar ao redor de algum valor mesmo que as observações não sejam totalmente independentes entre si.</p>
</div>
<div id="usando-matrizes" class="section level1">
<h1>Usando Matrizes</h1>
<p>Ao invés de simularmos uma sequência de transições e só depois calcularmos as proporções dos estados podemos fazer isso com matrizes. Para isso multiplicamos a matriz de transição pela matriz de probabilidades iniciais. O resultado é então multiplicado pela matriz de transição. Esse processo é repetido até o número de iterações, ou tempo, que queremos que a cadeia tenha.</p>
<pre class="r"><code>niter = 500

step =  initial_prob %*% transition_matrix
for (i in 1:niter){
    step = step %*% transition_matrix
}

step</code></pre>
<pre><code>##        repouso atividade
## [1,] 0.8333333 0.1666667</code></pre>
<pre class="r"><code># sim_prop = data.frame(x = 1:niter, y = apply(sim, 1, function(x){sum(x == 1)/nchains}))
# 
# ggplot(sim_prop, aes(x, y)) +
#       geom_line() +
#       labs(x = &quot;Iteration&quot;,
#            y = &quot;Prop.&quot;) +
#       theme_minimal(base_size = 16)</code></pre>
</div>
<div id="outros-links" class="section level1">
<h1>Outros Links</h1>
<ul>
<li><a href="https://willhipson.netlify.app/post/markov-sim/markov_chain/" class="uri">https://willhipson.netlify.app/post/markov-sim/markov_chain/</a></li>
<li><a href="https://a-little-book-of-r-for-bioinformatics.readthedocs.io/en/latest/src/chapter10.html" class="uri">https://a-little-book-of-r-for-bioinformatics.readthedocs.io/en/latest/src/chapter10.html</a></li>
<li><a href="http://recologia.com.br/2013/03/13/um-exemplo-de-markov-chain/" class="uri">http://recologia.com.br/2013/03/13/um-exemplo-de-markov-chain/</a></li>
<li><a href="https://towardsdatascience.com/markov-models-and-markov-chains-explained-in-real-life-probabilistic-workout-routine-65e47b5c9a73" class="uri">https://towardsdatascience.com/markov-models-and-markov-chains-explained-in-real-life-probabilistic-workout-routine-65e47b5c9a73</a></li>
<li><a href="https://www.stat.auckland.ac.nz/~fewster/325/notes/ch8.pdf" class="uri">https://www.stat.auckland.ac.nz/~fewster/325/notes/ch8.pdf</a></li>
</ul>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
